{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform as sys_pf\n",
    "# if sys_pf == 'darwin':\n",
    "#     import matplotlib\n",
    "#     matplotlib.use(\"TkAgg\")\n",
    "! pip install simpleitk\n",
    "%matplotlib inline  \n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import SimpleITK as sitk\n",
    "from scipy import ndimage\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (256,256,176)\n",
    "\n",
    "# Read in transformed images\n",
    "def read_file(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\",\")\n",
    "    data = np.reshape(data,image_shape)\n",
    "    return data\n",
    "\n",
    "# Read in non-transformed images\n",
    "def read_original(filename):\n",
    "    reader = sitk.ImageFileReader()\n",
    "    reader.SetImageIO(\"NiftiImageIO\")\n",
    "    reader.SetFileName(filename)\n",
    "    image = reader.Execute()\n",
    "\n",
    "    # img1 = sitk.ReadImage(folder + item)  # alternative way to pull in image\n",
    "\n",
    "    # convert image into np array & perform fft\n",
    "    img = sitk.GetArrayFromImage(image)\n",
    "    # Transpose the image so the first axis is Anterior-Posterior\n",
    "    img = np.transpose(img, (2,1,0))\n",
    "    return img \n",
    "\n",
    "def visualize(orig, new):\n",
    "    plt.figure(figsize= (20,20))\n",
    "    plt.subplot(121), plt.imshow(orig, cmap='gray')\n",
    "    plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122), plt.imshow(new, cmap='gray')\n",
    "    plt.title('New'), plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "def visualize3(orig, blur, predict):\n",
    "    plt.figure(figsize= (30,30))\n",
    "    plt.subplot(131), plt.imshow(orig, cmap='gray')\n",
    "    plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(132), plt.imshow(blur, cmap='gray')\n",
    "    plt.title('Blurred'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(133), plt.imshow(predict, cmap='gray')\n",
    "    plt.title('Predicted'), plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20,20))\n",
    "plt.subplot(121), plt.imshow(orig[100], cmap='gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(mod[100], cmap='gray')\n",
    "plt.title('New'), plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = read_file('gdrive/My Drive/NU_Rad/transforms/M02_motion5_trans.txt.gz')\n",
    "orig = read_original('gdrive/My Drive/NU_Rad/mris/M02.nii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc = 100\n",
    "plt.figure(figsize= (20,20))\n",
    "plt.subplot(121), plt.imshow(orig[slc], cmap='gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(new[slc], cmap='gray')\n",
    "plt.title('New'), plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Preprocessing\n",
    "# Data- Slice range from 70 to 220\n",
    "# Flatten each image\n",
    "# keras.utils.normalize each image\n",
    "# reshape back\n",
    "\n",
    "#   Architecture\n",
    "\n",
    "# Input layer\n",
    "\n",
    "# 2d convolution\n",
    "# activation- relu\n",
    "# 2d convlution\n",
    "# activation- relu\n",
    "\n",
    "# loss = mse\n",
    "\n",
    "\n",
    "# TO DO-\n",
    "# Double check the normalization function by multiplying output slice by max val & visualizing\n",
    "# Put together full pipeline taking in all mris\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Concatenate, Add, Average, Input, Dense, Flatten, BatchNormalization, Activation, LeakyReLU, Reshape\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from sklearn import preprocessing as prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(t_filenames, o_filenames, min_slc = 10, max_slc = 166):\n",
    "    # Takes in the files of the transformed images and the originals to create the pairs\n",
    "    # Also sets the min and max slice numbers to take in\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for i in range(len(t_filenames)):\n",
    "        print('Generating data for: ' + t_filenames[i])\n",
    "        x_mri = read_file(t_filenames[i])\n",
    "        y_mri = read_original(o_filenames[i])\n",
    "        \n",
    "        # Tranpose the images to left-right slices instead of anterior-posterior\n",
    "        x_mri = np.transpose(x_mri, (2,1,0))\n",
    "        y_mri = np.transpose(y_mri, (2,1,0))\n",
    "        for ii in np.arange(min_slc, max_slc+1):\n",
    "            x_data.append(x_mri[ii])\n",
    "            y_data.append(y_mri[ii])\n",
    "    # Shape of x & y will be [# slices, 256, 176]\n",
    "#     x_data = norm_slices(x_data)\n",
    "#     y_data = norm_slices(y_data)\n",
    "    return x_data, y_data\n",
    "\n",
    "# Normalizes each image slice\n",
    "def norm_slices (data):    \n",
    "    orig_shape = np.shape(data)\n",
    "    new_shape = np.reshape(data, (list(orig_shape)[0], list(orig_shape)[1] * list(orig_shape)[2]))\n",
    "    new_shape_norm = tf.keras.utils.normalize(new_shape, axis=0, order=2)\n",
    "    return np.reshape(new_shape_norm, orig_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_folder = 'gdrive/My Drive/NU_Rad/transforms/'\n",
    "orig_folder = 'gdrive/My Drive/NU_Rad/mris/'\n",
    "X_filenames = []\n",
    "y_filenames = []\n",
    "for item in os.listdir(trans_folder):\n",
    "    if item.endswith(\"_trans.txt.gz\"):\n",
    "        X_filenames.append(trans_folder + item)\n",
    "        y_filenames.append(orig_folder + item[:3] + '.nii')\n",
    "\n",
    "# X, y = generate_data(['gdrive/My Drive/NU_Rad/transforms/M02_motion5_trans.txt.gz'], ['gdrive/My Drive/NU_Rad/mris/M02.nii'])\n",
    "X, y = generate_data(X_filenames, y_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (3611, 256, 256, 1))\n",
    "y = np.reshape(y, (3611, 256, 256))\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5,5), padding='same', input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(1))\n",
    "model.add(Reshape((256,256)))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=10, validation_split=0.1, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict, y_predict = generate_data(['gdrive/My Drive/NU_Rad/transforms/M02_motion5_trans.txt.gz'], ['gdrive/My Drive/NU_Rad/mris/M02.nii'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_slice = 120\n",
    "X_input = np.reshape(X_predict[predict_slice], (1, 256, 256, 1))\n",
    "predict_out = model.predict(np.array(X_input))\n",
    "\n",
    "output = np.reshape(predict_out, (256, 256))\n",
    "# output = output*690\n",
    "visualize3(y_predict[predict_slice], X_predict[predict_slice], output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
